{
    "contents" : "---\ntitle: \"Practical Machine Learning - Human Activity Recognition\"\nauthor: \"Erik\"\ndate: \"06/14/2015\"\noutput: html_document\n---\n\nExecutive summary\n=================\n\nThe Weight Lifting Exercises (WLE) dataset was produced by having 6 participants performing dumbbell curls properly and improperly while activities were recorded by 4 \"on-body\" sensors (footnote 1). Using a random forest method, I was able to generate a model which can correctly assign activity quality with an out of sample error rate of 0.9%, as confirmed by cross-validation. This algorithm was then used to correctly classify unknown activity quality in the \"pml=testing.csv\" data set.\n\nSet Seed and Load Data\n-------------\n\nIn preparation for analysis, the random number seed was set and the data were loaded from csv files downloaded from the course website. Setting the random number seed allows the generation of the same random numbers every time the R markdown is run, which makes the data more easily reproduced. R packages ISLR, caret, Hmisc, RANN, ggplot2, and rattle were loaded into R studio.\n\n```{r, echo=FALSE}\n#take these out\nlibrary(ISLR)\nlibrary(caret)\nlibrary(Hmisc)\nlibrary(RANN)\nlibrary(ggplot2)\nlibrary(rattle)\n```\n```{r, echo=TRUE, cache=TRUE}\nset.seed(365)\npml.training<-read.csv(\"pml-training.csv\")\npml.testing<-read.csv(\"pml-testing.csv\")\n```\n\nBuilding the model \n================\n\nData Slicing\n------------------\n\nThe training set data were then sliced into train and test segments (60/40). By developing the model entirely on a subset of the training data, the remainder of the training set can be used for cross-validation and serves as a good measure of the out of sample error rate (the error rate when applying the model to new data).\n\n```{r, echo=TRUE}\ninTrain<-createDataPartition(y=pml.training$classe,p=0.6,list=FALSE)\n\ntrain<-pml.training[inTrain,]\ntest<-pml.training[-inTrain,]\n```\n\nPre-processing\n----------------\n\nThis training set was then processed to remove columns where the variable was essentially constant (these are not useful in the model), and missing data was imputed using the knnImpute method. Imputing was performed for all sensor data columns in the data set (columns 8, through the next-to-last column which was the \"classe\" exercise quality factor). Imputing missing data prevents us from needing to discard data points just because another data point is missing in that set.\n\n```{r, echo=TRUE}\nremoveColumns=nearZeroVar(x=train,freqCut=95/5)\n\ntrain<-train[,-removeColumns]\n\nimputeObj=preProcess(train[,8:ncol(train)-1],method=\"knnImpute\")\ntrain[,8:ncol(train)-1]<-predict(imputeObj,train[,8:ncol(train)-1])\n```\n\nFitting a Linear Regression Model\n----------------\n\nThe data were processed further to fit a linear model. An additional column ('classn') was created to change the exercise quality factor (A,B,C,D,E) to a numeric value (1,2,3,4,5). A linear model was fit (lm1), and predictions relative to true values are plotted in Figure 1. Obviously, the predictions all overlap and would not be good indicators of exercise quality metrics, even on the training set. This is not surprising, because linear regression often has poor performance in nonlinear settings. R also produces a warning that the fit is \"rank-deficient\", meaning that the data is unable to fit this model.\n\n```{r, echo=TRUE}\nfor(i in 1:nrow(train)){\n  train$classn[i]<-utf8ToInt(as.character(train$classe[i]))-64\n}\n\nx<-colnames(train[,c(8:ncol(train)-2,ncol(train))])\ntrain2<-train[,c(8:ncol(train)-2,ncol(train))]\n\ncolnames(train2)<-x\nlm1<-lm(classn~.,data=train2)\npred<-predict(lm1,train2)\nqplot(classn,pred,data=train2)\nprint(\"Figure 1. Linear model fit to training dataset.\")\n\n```\n\nRandom Forest Model\n-----------------\n\nA random forest model is a much better choice for this multivariate data. By generating decision trees with bootstrapped samples, and then bootstrapping variables at each decision point, it is well suited to work with large sets of variables. \n\nThe data were then reprocessed to remove the \"classn\" column, and a random forest method was used to generate a model. \n\n```{r, echo=TRUE}\n\nx<-colnames(train[,c(8:ncol(train)-1)])\ntrain2<-train[,c(8:ncol(train)-1)]\ncolnames(train2)<-x\n\n\nmodFit<-train(classe~.,method=\"rf\",data=train2,prox=TRUE)\nprint(modFit)\nprint(\"Figure 2. Summary of parameters in random forest model\")\n\n\npredTrain=predict(modFit,train2)\ntrain2$predRight<-predTrain==train2$classe\nprint(table(predTrain,train2$classe))\nprint(\"Figure 3. Comparison of predicted and true values on the training set\")\n\n```\nCross Validation\n---------------\n\nThe cross-validation data set was processed idenitcally to the training set and run through the random forest algorithm. Comparing the number of correct predictions (7773) out of the validation data set (7846) gives an out of sample error rate of 0.9%.\n\n```{r, echo=TRUE}\n\ntest<-test[,-removeColumns]\n\ntest[,8:ncol(test)-1]<-predict(imputeObj,test[,8:ncol(test)-1])\n\npredTest=predict(modFit,test)\ntest$predRight<-predTest==test$classe\nprint(table(predTest,test$classe))\nprint(\"Figure 3. Comparison of predicted and true values on the cross-validation set\")\n\n#out of sample error\nOSE<-1-(sum(test$predRight/nrow(test)))\nprint(paste(\"The out of sample error is \",toString(OSE*100),\"%, with \",toString(sum(test$predRight)),\"correct predicitions out of \",toString(nrow(test),\" samples.\")))\n\n```\nAssign Excercise Quality Categories to Testing Data\n-------------------------------------------\n\nFinally, process the testing data and use the model created and cross-validated to assign excercise quality for the 20 unknown samples:\n\n```{r, echo=TRUE}\n\n#remove same columns as from training sets\npml.testing<-pml.testing[,-removeColumns]\n\n\n#test data has \"problem ID\" column instead of classe\npml.testing[,8:ncol(pml.testing)-1]<-predict(imputeObj,pml.testing[,8:ncol(pml.testing)-1])\n\n\npredTesting=predict(modFit,pml.testing)\npml.testing$pred<-predTesting\nans<-pml.testing$problem_id\nans<-cbind(ans,as.character(pml.testing$pred))\n\nprint(ans)\nprint(\"Figure 5. Predicted exercise quality category for 20 unknown samples in testing dataset.\")\n \n\n\n```\n\n\n\n\n1)  Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. Qualitative Activity Recognition of Weight Lifting Exercises. Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human '13) . Stuttgart, Germany: ACM SIGCHI, 2013.\n\nRead more: http://groupware.les.inf.puc-rio.br/har#ixzz3d6LWGFeH",
    "created" : 1434812648107.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3636865765",
    "id" : "13604755",
    "lastKnownWriteTime" : 1434418416,
    "path" : "~/MOOC/Coursera - predictive machine learning/Practical Machine Learning project/pml.Rmd",
    "project_path" : null,
    "properties" : {
    },
    "source_on_save" : false,
    "type" : "r_markdown"
}